---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

As autonomous systems become more prevalent, quickly becoming more ingrained in everyday life, the practical deployment of autonomy raises concerns about the reliability of such systems to ensure correct or safe operation. Despite recent advances, data-driven control algorithms are often fragile, and susceptible to errors stemming from limited data availability which can limit their applicability in new, unseen scenarios. My research seeks to answer the question: _How can we develop reliable data-driven methods for autonomous control, and detect and mitigate potential errors that arise in data-driven domains?_ My work focuses on the development of new theory and algorithms at the intersection of learning and control. First, I endeavor to develop tools that seamlessly integrate model-based and data-driven control to overcome the inherent limitations of learning and data in control applications. Specifically, I aim to explore new methods to incorporate prior model information in data-driven algorithms, such as prior knowledge of the dynamics or system properties, in order to ensure correctness, reduce the overt dependence on data, and enable broader generalization of learned models. Second, to address the unique challenges that arise from data in control settings, I aim to develop a new theory of robustness that accounts for the role of data in controller performance. In particular, I seek to focus on controller synthesis by reformulating data-driven control problems with data uncertainty in mind, for instance by introducing additional constraints that ensure correctness with respect to the data and to avoid out-of-distribution errors. Third, I seek to develop a statistical framework for human-in-the-loop control that uses tools from functional analysis to categorize human behavior models for the purpose of designing controllers which are responsive to user needs and preferences.


Integrating Model-Based and Data-Driven Control
======
Traditional model-based techniques match mathematical equations to observed physical phenomena, but face practical limitations as systems become increasingly more complex, and have limited utility in highly uncertain environments with poorly characterized stochastic disturbances. As such, data-driven methods, which use real-time observations and historical data to learn a model and a controller, offer an attractive alternative due to their ability to adapt and learn in response to the data. In this area, I have developed computationally efficient data-driven techniques for control using the theory of reproducing kernel Hilbert spaces, including joint chance-constrained optimization in collaboration with Thomas Lew and Prof. Marco Pavone (Stanford) and dynamic programs, that can be solved as a linear program using convex optimization techniques. These results are notable due to the traditionally challenging nature of the problems, and have the potential to define a novel framework to solve approximate stochastic optimal control problems for many systems which were previously impossible or exceptionally difficult to solve. 

Nevertheless, in the absence of a physics-based model, purely data-driven algorithms based in learning theory provide an inherently limited view of the observed system, which limits their practical utility--in part because behaviors that are not captured by the data are not accounted for in the learned model. Learning algorithms are designed to avoid implicit biases. However, for dynamical systems, such biases impart important domain knowledge and can contain useful information regarding the system behavior and its properties. In recent work in collaboration with Prof. Ufuk Topcu (UT Austin), we demonstrated that incorporating model-based knowledge of the system (even when such knowledge is potentially incorrect) can improve the efficiency and accuracy of data-driven algorithms. Learning-based methods in control are often treated as a silver bullet, but an honest assessment of current approaches demonstrates clear limitations that must be overcome for their practical use and deployment. I am interested in developing methods that integrate model-based knowledge with data-driven techniques to overcome such limitations, and to find new ways to incorporate prior system knowledge into data-driven control that improve efficiency, algorithmic stability, and generalize better when data alone is insufficient. In future work, I aim to explore the use of such tools on physical systems, and to explore new types of learning algorithms which take model-based knowledge into account. The further development of such techniques has great potential to establish a holistic control framework that can bridge the gap between model-based theory and statistical learning theory, a cornerstone of data-driven control.


Developing a New Theory of Robustness for Data-Driven Control
======
Without a physics-based model of the system, data-driven approaches rely upon knowledge provided implicitly by the data via statistical inference, which is inherently limited by the amount and scope of the collected data. Operating in new environments or under dynamically changing conditions can lead to a mismatch between the observed system behavior and the learned system behavior as described by the data. Such discrepancies are known as out-of-distribution (OOD) errors, and can lead to incorrect predictions and, consequently, unpredictable or unsafe outcomes by the autonomous controller. In autonomy, the effects of OOD errors are poorly characterized, in part since the effects are typically observed downstream. Such errors present a significant challenge, since they must be detected and corrected at runtime, and are often not observable during the design phase. In particular, this means autonomy must be robust to potential changes in the data. This presents an immediate need for control algorithms that are OOD-aware, that are adaptive and responsive to OOD errors. 

Traditional theories of robustness seek to account for heavy-tailed distributions and rare events, but often fail to capture the effects data has on the learned model. In past work, we have observed that proper selection of the data and the corresponding learning model has a significant impact on the performance and reliability of autonomous controllers. This motivates the need for a new theory of robustness in data-driven control--specifically, resistance to OOD errors, data deficiencies, and changes in the data. I am interested in exploring the effects of OOD errors in data-driven algorithms, including detection and mitigation strategies, and developing algorithms that can account for OOD errors online. In particular, I plan to explore data-driven control algorithms that are OOD-aware, meaning they are designed to be robust to changes in the data and adaptable to potential changes when they arise. 


Creating a Framework for Human-in-the-Loop Analysis and Control
======
At present, we have just begun to formulate and answer some of the more meaningful questions surrounding human interactions with autonomy. Human involvement substantially complicates the design and testing of autonomy for human-in-the-loop (HITL) systems--in particular due to the heterogeneous nature of human behavior and decision-making and the fact that humans do not behave `optimally'. Thus, in human-centered contexts, notions of safety and reliability take on new meanings and are made even more complex, since human preferences and behaviors (often based in psychological and physiological effects) are unmodeled, poorly characterized, or simply unknown. This raises questions about how autonomy _should_ operate in human-centered environments, and remains an open question.

One area I am particularly interested in is developing a functional/probabilistic framework for human-centered autonomy to begin characterizing human behavior. As part of the NSF Cyber-Physical Systems (CPS) Frontiers grant with my advisor, Dr. Meeko Oishi (UNM), and in collaboration with student lab members and PIs at Purdue, we have begun to develop mathematical and statistical tools for analysis of HITL systems for autonomous vehicles. As part of this team, I have pioneered an approach that uses functional analysis and simple, efficient probability metrics to categorize human behavior and detect trends in human learning. Our goal is to develop a framework for analysis and control that is responsive to humans in the loop. Specifically, we seek a framework that can categorize and track human behavior trends in order to design controllers that adapt to behavioral changes and perceived human preferences (for instance in response to driver characteristics). This has the potential to change how human operators in autonomous and semi-autonomous vehicles are considered during the design stage for assistive and safety takeover technologies. I aim to develop and test such tools using HITL experimental driving and robotics testbeds. 


Broader Impacts for Society
======
My research advocates for a balanced approach to critically evaluate the risks and biases of learning-based and data-driven control. The pursuit of robustness is a necessary step, but is insufficient. A more nuanced perspective that is centered around humans is needed to ensure that autonomy is viewed as reliable and safe. 

My research operates at the intersection of humans, data, and controls. By acknowledging the limitations of purely data-driven algorithms and advocating for the integration of model-based knowledge, my work seeks to enhance the safety and reliability of autonomous systems. Moreover, focusing on human-centered design provides a bridge between theoretical frameworks and the practical, real-world deployment of autonomy, with the ultimate goal of developing autonomous systems that not only perform optimally but are responsive to the intricacies of human interaction. Through this perspective, my research aims to develop _reliable_ autonomy, that is not just error-free but also aligns with user expectations and needs. 